{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelEvaluationConfig():\n",
    "    HDFmodel_path : Path\n",
    "    model_path : Path\n",
    "    test_images_path : Path\n",
    "    test_blur_images_path : Path\n",
    "    test_clean_images_path : Path\n",
    "    test_blurimages_source: str\n",
    "    test_cleanimages_source : str\n",
    "    loss:str\n",
    "    optimizer: str\n",
    "    metrics:list\n",
    "    batch_size: int\n",
    "    epochs:int\n",
    "    model_history_path :Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder.constants import filepath\n",
    "from autoencoder import logger\n",
    "from autoencoder.utils.util_functions import read_yaml, create_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager():\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = filepath.CONFIG_FILE_PATH,\n",
    "        param_filepath = filepath.PARAMS_FILE_PATH,\n",
    "        secret_filepath = filepath.SECRET_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(param_filepath)\n",
    "        self.secret = read_yaml(secret_filepath)\n",
    "\n",
    "        create_dir([self.config.data_paths.test_images_path])\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        data_config = self.config.data_paths\n",
    "        model_config = self.config.model_paths\n",
    "        param_config = self.params\n",
    "\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            HDFmodel_path=model_config.HDFmodel_path,\n",
    "            model_path=model_config.model_path,\n",
    "            test_images_path=data_config.test_images_path,\n",
    "            test_blur_images_path=data_config.test_blur_images_path,\n",
    "            test_clean_images_path=data_config.test_clean_images_path,\n",
    "            test_blurimages_source= data_config.test_blurimages_source,\n",
    "            test_cleanimages_source = data_config.test_cleanimages_source,\n",
    "            loss=param_config.loss,\n",
    "            optimizer=param_config.optimizer,\n",
    "            metrics=param_config.metrics,\n",
    "            batch_size=param_config.batch_size,\n",
    "            epochs=param_config.epochs,\n",
    "            model_history_path=model_config.model_history_path\n",
    "\n",
    "        )\n",
    "\n",
    "        return model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gdown\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Model Training\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import Model, Input, regularizers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Conv2D, Flatten\n",
    "from keras.layers import Reshape, Conv2DTranspose, BatchNormalization, Add\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from urllib.parse import urlparse\n",
    "from mlflow.models import infer_signature\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self, eval_config : ModelEvaluationConfig):\n",
    "        self.eval_config = eval_config\n",
    "\n",
    "    def download_test_data(self, source_url:str,dest_path:str  ) ->str:\n",
    "        try:\n",
    "            folder_id = source_url.split(\"/\")[-1]\n",
    "            folder_id = folder_id.split(\"?\")[0]\n",
    "\n",
    "            # api_token = self.download_config.gdrive_api_key\n",
    "            api_url = f\"https://www.googleapis.com/drive/v3/files?q='{folder_id}'+in+parents&key=AIzaSyD9C-ouf5DmOrKzH5p4DsLcZ6k8FB-o13I\"\n",
    "            logger.info(f\"Getting Response from Gdrive api_url : {api_url}\")\n",
    "            response = requests.get(api_url)\n",
    "            logger.info(f'response : {response.status_code}')\n",
    "            if response.status_code==200:\n",
    "                logger.info(\"Response 200 OK\")\n",
    "                files = response.json().get('files', [])\n",
    "                logger.info(f'Downloading files in folder : {dest_path}')\n",
    "                for file in files:\n",
    "                    file_id = file['id']\n",
    "                    file_name = file['name']\n",
    "                    download_url = f'https://drive.google.com/uc?id={file_id}'\n",
    "                    \n",
    "                    # Download the file using gdown\n",
    "                    gdown.download(download_url, os.path.join(dest_path, file_name), quiet=False)\n",
    "                logger.info(\"**** Test Images Downloaded ****\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def download_testblurimages(self):\n",
    "        try:\n",
    "            create_dir([self.eval_config.test_blur_images_path])\n",
    "            logger.info(f'Downloading Blur Images Test Data into {self.eval_config.test_blur_images_path}')\n",
    "            self.download_test_data(self.eval_config.test_blurimages_source, self.eval_config.test_blur_images_path)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def download_testcleanimages(self):\n",
    "        try:\n",
    "            create_dir([self.eval_config.test_clean_images_path])\n",
    "            logger.info(f'Downloading Clean Images Test Data into {self.eval_config.test_clean_images_path}')\n",
    "            self.download_test_data(self.eval_config.test_cleanimages_source, self.eval_config.test_clean_images_path)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def psnr_metric(self, y_true, y_pred):\n",
    "        return tf.image.psnr(y_true, y_pred, max_val=1.0)\n",
    "    \n",
    "\n",
    "    def image_to_array(self, folder_path) -> np.ndarray:\n",
    "        array = []\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            try:\n",
    "                img = image.load_img(img_path)\n",
    "                img = image.img_to_array(img)\n",
    "                img = img/255.0\n",
    "                array.append(img)\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "        logger.info(\"Image Data Successfully Converted into numpy array\")\n",
    "        return np.array(array)\n",
    "\n",
    "    def evaluate_model(self) -> str:\n",
    "        logger.info(f'Loading Model from {self.eval_config.HDFmodel_path}')\n",
    "        try:\n",
    "            model = tf.keras.models.load_model(self.eval_config.HDFmodel_path,\n",
    "                                   custom_objects={'mse': tf.keras.losses.MeanSquaredError()})\n",
    "\n",
    "            x_test = self.image_to_array(self.eval_config.test_blur_images_path)\n",
    "            y_test = self.image_to_array(self.eval_config.test_clean_images_path)\n",
    "            logger.info('Evaluating Model on Test Data')\n",
    "\n",
    "            # Get model predictions (deblurred images)\n",
    "            y_pred = model.predict(x_test)\n",
    "\n",
    "            # Calculate PSNR for each image and average the scores\n",
    "            psnr_values = [self.psnr_metric(y_true, y_pred).numpy() for y_true, y_pred in zip(y_test, y_pred)]\n",
    "            avg_psnr = np.mean(psnr_values)\n",
    "\n",
    "            logger.info(f'Average PSNR on Test Data: {avg_psnr}')\n",
    "            # return f'Average PSNR: {avg_psnr}'\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f'Error occurred during model evaluation: {e}')\n",
    "            raise e\n",
    "\n",
    "    def log_into_mlflow(self) ->str:\n",
    "        os.environ['MLFLOW_TRACKING_USERNAME'] = 'Kamal254'\n",
    "        os.environ['MLFLOW_TRACKING_PASSWORD'] = '3cbdb442b5873e54a9130d1e83862bb2e7993f55'\n",
    "\n",
    "        remote_server_uri = \"https://dagshub.com/Kamal254/Deblur-Image-autoencoder.mlflow\"\n",
    "        mlflow.set_tracking_uri(remote_server_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        logger.info(\"Saving Experiments to the mlflow\")\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            model = tf.keras.models.load_model(self.eval_config.HDFmodel_path,\n",
    "                                   custom_objects={'mse': tf.keras.losses.MeanSquaredError()})\n",
    "\n",
    "            x_test = self.image_to_array(self.eval_config.test_blur_images_path)\n",
    "            y_test = self.image_to_array(self.eval_config.test_clean_images_path)\n",
    "            \n",
    "            logger.info(\"Logging All the Parameters into mlflow\")\n",
    "            mlflow.log_param(\"Loss\", self.eval_config.loss)\n",
    "            mlflow.log_param(\"optimizer\",self.eval_config.optimizer)\n",
    "            mlflow.log_param(\"metrics\",self.eval_config.metrics)\n",
    "            mlflow.log_param(\"batch_size\",self.eval_config.batch_size)\n",
    "            mlflow.log_param(\"epochs\",self.eval_config.epochs)\n",
    "\n",
    "            logger.info(\"Logging training metrics into mlflow\")\n",
    "            with open(self.eval_config.model_history_path, 'r') as f:\n",
    "                history = json.load(f)\n",
    "\n",
    "            for epoch in range(self.eval_config.epochs):\n",
    "                mlflow.log_metric('train_loss', history['loss'][epoch], step=epoch)\n",
    "                mlflow.log_metric('train_accuracy', history['acc'][epoch], step=epoch)\n",
    "\n",
    "            logger.info(\"Logging Evaluation metrics into mlflow\")\n",
    "\n",
    "            y_pred = model.predict(x_test)\n",
    "\n",
    "            # Calculate PSNR for each image and average the scores\n",
    "            psnr_values = [self.psnr_metric(y_true, y_pred).numpy() for y_true, y_pred in zip(y_test, y_pred)]\n",
    "            avg_psnr = np.mean(psnr_values)\n",
    "            mlflow.log_metric(' peak signal-to-noise ratio ', avg_psnr)\n",
    "            if tracking_url_type_store != \"file\":\n",
    "                mlflow.keras.log_model(model, \"model\", registered_model_name=\"autoencoder\")\n",
    "            else:\n",
    "                mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-24 15:22:33,327:INFO:util_functions:yaml file: ..\\config\\config.yaml loaded successfully]\n",
      "[2024-09-24 15:22:33,330:INFO:util_functions:yaml file: ..\\params.yaml loaded successfully]\n",
      "[2024-09-24 15:22:33,333:INFO:util_functions:yaml file: ..\\secret\\secrets.yaml loaded successfully]\n",
      "[2024-09-24 15:22:33,334:INFO:util_functions:Created directory at : ../artifacts/dataset/testingfolder]\n",
      "[2024-09-24 15:22:33,335:INFO:util_functions:Created directory at : ../artifacts/dataset/testingfolder/test_blur_images]\n",
      "[2024-09-24 15:22:33,336:INFO:3006049005:Downloading Blur Images Test Data into ../artifacts/dataset/testingfolder/test_blur_images]\n",
      "[2024-09-24 15:22:33,336:INFO:3006049005:Getting Response from Gdrive api_url : https://www.googleapis.com/drive/v3/files?q='1HHFORB79yvCz3Miy-fWPTVzC1avGGMxt'+in+parents&key=AIzaSyD9C-ouf5DmOrKzH5p4DsLcZ6k8FB-o13I]\n",
      "[2024-09-24 15:22:33,972:INFO:3006049005:response : 200]\n",
      "[2024-09-24 15:22:33,972:INFO:3006049005:Response 200 OK]\n",
      "[2024-09-24 15:22:33,972:INFO:3006049005:Downloading files in folder : ../artifacts/dataset/testingfolder/test_blur_images]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1s0s4FBVpMrAWILRFDfzkFGtLWg5qsfIh\n",
      "To: d:\\SONU\\folder c\\Desktop\\Portfolio Github Projects\\Deblur-Image-autoencoder\\artifacts\\dataset\\testingfolder\\test_blur_images\\SFHQ_pt2_00009963.jpg\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.40k/4.40k [00:00<00:00, 4.23MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1nG08YEd2Pigngye4hrM4LfxutUpCKe87\n",
      "To: d:\\SONU\\folder c\\Desktop\\Portfolio Github Projects\\Deblur-Image-autoencoder\\artifacts\\dataset\\testingfolder\\test_blur_images\\SFHQ_pt2_00009960.jpg\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.21k/4.21k [00:00<?, ?B/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1rwbhjgEFREwQkaJ6WTEbnFUlmFIqF7Rq\n",
      "To: d:\\SONU\\folder c\\Desktop\\Portfolio Github Projects\\Deblur-Image-autoencoder\\artifacts\\dataset\\testingfolder\\test_blur_images\\SFHQ_pt2_00009961.jpg\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.29k/4.29k [00:00<00:00, 4.30MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1tJi7D0DOBmWAFdQyw0OX8v4YgW-QNyCv\n",
      "To: d:\\SONU\\folder c\\Desktop\\Portfolio Github Projects\\Deblur-Image-autoencoder\\artifacts\\dataset\\testingfolder\\test_blur_images\\SFHQ_pt2_00009962.jpg\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.55k/4.55k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-24 15:22:52,454:INFO:3006049005:**** Test Images Downloaded ****]\n",
      "[2024-09-24 15:22:52,470:INFO:util_functions:Created directory at : ../artifacts/dataset/testingfolder/test_clean_images]\n",
      "[2024-09-24 15:22:52,470:INFO:3006049005:Downloading Clean Images Test Data into ../artifacts/dataset/testingfolder/test_clean_images]\n",
      "[2024-09-24 15:22:52,470:INFO:3006049005:Getting Response from Gdrive api_url : https://www.googleapis.com/drive/v3/files?q='1PDBJi8hLuaxDK3D3tsU-Uw5N0wySwP1X'+in+parents&key=AIzaSyD9C-ouf5DmOrKzH5p4DsLcZ6k8FB-o13I]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-24 15:22:53,119:INFO:3006049005:response : 200]\n",
      "[2024-09-24 15:22:53,136:INFO:3006049005:Response 200 OK]\n",
      "[2024-09-24 15:22:53,136:INFO:3006049005:Downloading files in folder : ../artifacts/dataset/testingfolder/test_clean_images]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1a2up2du77cgpwPzUvFtAH0NWU53Edm4C\n",
      "To: d:\\SONU\\folder c\\Desktop\\Portfolio Github Projects\\Deblur-Image-autoencoder\\artifacts\\dataset\\testingfolder\\test_clean_images\\SFHQ_pt2_00009960.jpg\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.87k/2.87k [00:00<?, ?B/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1uwsC0ELNXD598oEmOj3OAsHrCPZ5PtH_\n",
      "To: d:\\SONU\\folder c\\Desktop\\Portfolio Github Projects\\Deblur-Image-autoencoder\\artifacts\\dataset\\testingfolder\\test_clean_images\\SFHQ_pt2_00009963.jpg\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.96k/2.96k [00:00<?, ?B/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1AlfNbfUiZi9RvU64xlmsnImIrWIzT6N_\n",
      "To: d:\\SONU\\folder c\\Desktop\\Portfolio Github Projects\\Deblur-Image-autoencoder\\artifacts\\dataset\\testingfolder\\test_clean_images\\SFHQ_pt2_00009962.jpg\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.23k/3.23k [00:00<?, ?B/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1he_bDnNbzaeTs_FPxKfXw9qbkfxLKTqD\n",
      "To: d:\\SONU\\folder c\\Desktop\\Portfolio Github Projects\\Deblur-Image-autoencoder\\artifacts\\dataset\\testingfolder\\test_clean_images\\SFHQ_pt2_00009961.jpg\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.91k/2.91k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-24 15:23:10,662:INFO:3006049005:**** Test Images Downloaded ****]\n",
      "[2024-09-24 15:23:10,677:INFO:3006049005:Loading Model from ../artifacts/models/autoencoder.h5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-24 15:23:11,479:WARNING:saving_utils:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n",
      "[2024-09-24 15:23:11,537:INFO:3006049005:Image Data Successfully Converted into numpy array]\n",
      "[2024-09-24 15:23:11,544:INFO:3006049005:Image Data Successfully Converted into numpy array]\n",
      "[2024-09-24 15:23:11,544:INFO:3006049005:Evaluating Model on Test Data]\n",
      "[2024-09-24 15:23:12,371:WARNING:polymorphic_function:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001728CCA7C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767ms/step\n",
      "[2024-09-24 15:23:12,382:INFO:3006049005:Average PSNR on Test Data: 8.186097145080566]\n",
      "[2024-09-24 15:23:12,382:INFO:3006049005:Saving Experiments to the mlflow]\n",
      "[2024-09-24 15:23:13,432:WARNING:saving_utils:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n",
      "[2024-09-24 15:23:13,471:INFO:3006049005:Image Data Successfully Converted into numpy array]\n",
      "[2024-09-24 15:23:13,477:INFO:3006049005:Image Data Successfully Converted into numpy array]\n",
      "[2024-09-24 15:23:13,478:INFO:3006049005:Logging All the Parameters into mlflow]\n",
      "[2024-09-24 15:23:15,464:INFO:3006049005:Logging training metrics into mlflow]\n",
      "[2024-09-24 15:23:23,554:INFO:3006049005:Logging Evaluation metrics into mlflow]\n",
      "[2024-09-24 15:23:24,418:WARNING:polymorphic_function:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000172DE1B3CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/24 15:23:24 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/09/24 15:23:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'autoencoder'.\n",
      "2024/09/24 15:24:36 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: autoencoder, version 1\n",
      "Created version '1' of model 'autoencoder'.\n",
      "2024/09/24 15:24:36 INFO mlflow.tracking._tracking_service.client: üèÉ View run resilient-yak-52 at: https://dagshub.com/Kamal254/Deblur-Image-autoencoder.mlflow/#/experiments/0/runs/eeb7573055a745229ac2cf4c9bb6bcb7.\n",
      "2024/09/24 15:24:36 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/Kamal254/Deblur-Image-autoencoder.mlflow/#/experiments/0.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    model_eval_config = config_manager.get_model_evaluation_config()\n",
    "    model_evaluation = ModelEvaluation(model_eval_config)\n",
    "    model_evaluation.download_testblurimages()\n",
    "    model_evaluation.download_testcleanimages()\n",
    "    model_evaluation.evaluate_model()\n",
    "    model_evaluation.log_into_mlflow()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
